#' Generate Bootstrap Sample
#'
#' This function generates a bootstrap sample from the given predictors and response based on the specified value.
#'
#' @param X The matrix/data frame containing predictors.
#' @param y The response variable.
#' @param n The number of samples to generate.
#' @return A list containing the bootstrap sample of predictors and response.
#' @export
bootstrap_sample <- function(X,y, n) {
  num_rows <- nrow(X)
  sampled_indices <- sample(1:num_rows, size = n, replace = TRUE)
  sampled_data_x <- X[sampled_indices, ]
  sampled_data_y <- y[sampled_indices ]
  return(list(sample_X = sampled_data_x, sample_y=sampled_data_y))
}

#' Generate Predictions from Ensemble of Models
#'
#' This function generates predictions from an ensemble of regression models or classifiers.
#'
#' @param X The matrix/data frame containing predictors for which predictions are to be generated.
#' @param y The true response variable (for calculating accuracy or RMSE).
#' @param models A list containing the ensemble of trained regression models or classifiers.
#' @param model_type The type of regression model used for predictions. Options: "linear", "logistic", "ridge", "lasso", "elastic_net".
#' @param output_type The type of output (Regression or Classification).
#' @param lambda (Optional) The regularization parameter lambda for ridge, lasso, and elastic net regression.
#' @param K (Optional) The number of top most informative predictors to select.
#' @param alpha (Optional) The mixing parameter alpha for elastic net regression.
#' @return Predictions generated by the ensemble of models.
#' @details This function generates predictions using an ensemble of trained regression models or classifiers.
#'          It supports both regression and classification tasks. For regression, it calculates the mean prediction
#'          from all models. For classification, it uses majority voting to determine the final prediction.
#'          The function also calculates accuracy or RMSE based on the true response variable provided.
#' @export
predictions_models <- function(X,y,models,model_type, output_type,lambda,K,alpha) {
  X = one_hot_encode(X)
  X = data.frame(X)
  if (output_type == "Regression") {
    final_predictions <- numeric(nrow(X))
    for (i in 1:length(models)) {
      model <- models[[i]]$model

      X1 = X[ ,models[[i]]$predictors_names]

      if(model_type=="linear" || model_type=="logistic")
      { prediction <- predict(model, newdata = X) }
      else{

        if(is.null(lambda)){
          ps = prescreening(X1,y,K=K)
          family = ifelse((length(unique(y)) == 2),"binomial","gaussian")
          cat("Since Lambda is NULL, we will be using best lamda value for prediction\n")
          if(model_type=="ridge"){
            cv_fit <- cv.glmnet(as.matrix(ps$predictors), ps$response, alpha = 0, family = family, type.measure = "deviance", nfolds = 10)
          }else if(model_type=="lasso"){
            cv_fit <- cv.glmnet(as.matrix(ps$predictors), ps$response, alpha = 1, family = family, type.measure = "deviance", nfolds = 10)
          }else{
            cv_fit <- cv.glmnet(as.matrix(ps$predictors), ps$response, alpha = alpha, family = family, type.measure = "deviance", nfolds = 10)
          }
          lambda <- cv_fit$lambda.min
          prediction <- predict(model, newx = as.matrix(X1), s = lambda)
        }
        else{
          prediction <- predict(model, newx = as.matrix(X1), s = lambda)
        }
      }

      final_predictions <- final_predictions + prediction

      rmse_model <- sqrt(mean((y - as.numeric(prediction))^2))
    }
    final_predictions <- final_predictions / length(models)
    rmse_model <- sqrt(mean((y - as.numeric(final_predictions))^2))
    cat("RMSE for predicted values :", rmse_model, "\n")
    return(final_predictions)
  }
  else if (output_type == "Classification") {
    final_predictions <- matrix(NA, nrow = nrow(X), ncol = length(models))
    for (i in 1:length(models)) {
      model <- models[[i]]
      X1 = X[ ,model$predictors_names]



      if(model_type=="linear" || model_type=="logistic")
      { prediction <- predict(model$model, newdata = data.frame(X1), type = "response")
      prediction <- ifelse(prediction > 0.5, 1, 0)}
      else {
        if(is.null(lambda)){
          ps = prescreening(X,y,K=K)
          family = ifelse((length(unique(y)) == 2),"binomial","gaussian")
          cat("Since Lambda is NULL, we will be using best lamda value for prediction\n")
          if(model_type=="ridge"){

            cv_fit <- cv.glmnet(as.matrix(ps$predictors), ps$response, alpha = 0, family = family, type.measure = "deviance", nfolds = 10)
          }else if(model_type=="lasso"){
            cv_fit <- cv.glmnet(as.matrix(ps$predictors), ps$response, alpha = 1, family = family, type.measure = "deviance", nfolds = 10)
          }else{
            cv_fit <- cv.glmnet(as.matrix(ps$predictors), ps$response, alpha = alpha, family = family, type.measure = "deviance", nfolds = 10)
          }
          lambda <- cv_fit$lambda.min
          model_predictions <- predict(model$model, newx = as.matrix(X1), s = lambda, type = "response")
        }
        else{
          model_predictions <- predict(model$model, newx = as.matrix(X1), s = lambda, type = "response")
        }
        prediction <- ifelse(model_predictions > 0.5, 1, 0)
      }

      final_predictions[, i] <- prediction
    }
    majority_vote <- apply(final_predictions, 1, function(x) {
      names(which.max(table(x)))
    })


    acc=sum(majority_vote==as.character(y))
    cat("Accuracy of predicted values are", (acc/length(y)),"\n")
    return(majority_vote)
  } else {
    stop("Unsupported output type.")
  }
}

#' Perform Bagging with Various Regression Models
#'
#' This function performs bagging (bootstrap aggregation) with various regression models.
#'
#' @param X The matrix/data frame containing predictors.
#' @param y The response variable.
#' @param test_x The matrix/data frame containing predictors for the test data.
#' @param test_y The response variable for the test data.
#' @param model_type The type of regression model to use for bagging. Options: "linear", "logistic", "ridge", "lasso", "elastic_net".
#' @param n_models The number of models to include in the bagging ensemble.
#' @param lambda (Optional) The regularization parameter lambda for ridge, lasso, and elastic net regression.
#' @param K (Optional) The number of top most informative predictors to select.
#' @param alpha (Optional) The mixing parameter alpha for elastic net regression.
#' @param res (Optional) Specify if you want to manually specify the response variable.
#' @return A list containing the final predictions and variable importance scores.
#' @details This function performs bagging by training multiple regression models using bootstrap samples
#'          from the training data. It supports various regression model types including linear regression,
#'          logistic regression, ridge regression, lasso regression, and elastic net regression. The number of
#'          models to include in the bagging ensemble is specified by the parameter n_models. The final predictions
#'          are generated using the trained models on the provided test data. Variable importance scores are also
#'          calculated based on the frequency of predictor variables appearing in the ensemble of models.
#' @examples
#' ## Test case 1 : Binary
#' set.seed(42)
#' p<-1000
#' n<-100
#' X5 <- matrix(rnorm(p * n), nrow = n, ncol = p)
#' Y5 <- sample(0:1, n, replace = TRUE)
#' bagging(X5,Y5,test_x=X5,test_y=Y5, model_type = "ridge", n_models = 5,alpha=0.5)
#'
#' @examples
#' ## Test case 2 : Continuos
#' p <- 1000  # Number of predictors
#' n <- 100   # Number of observations
#' # Generate random data
#' set.seed(42)
#' X4 <- data.frame(matrix(rnorm(p * n), nrow = n, ncol = p))
#' Y4 <- rnorm(n)
#' bagging(X5,Y5,test_x=X5,test_y=Y5, model_type = "ridge", n_models = 5,alpha=0.5)
#'
#'
#' @export
bagging <- function(X,y,test_x=NULL,test_y=NULL, model_type, n_models,lambda=NULL,K =NULL,alpha=NULL,res=NULL) {
  X <- data.frame(X)
  test_x <- data.frame(test_x)
  res2=NULL
  cor_threshold=NULL
  if (ncol(X) >= 2*nrow(X)) {
    cat("The number of predictors p is much greater than the number of observations n.\n",
        "Consider specifying the K parameter to perform pre-screening for top K most informative predictors.\n")
    res <- readline(prompt="Do you want to specify the number of top K most informative predictors? (yes/no): ")
    if (tolower(res) == "yes") {

      K <- as.integer(readline(prompt="Please enter the value of K: "))
      if (K < 1 || K > ncol(X)) {
        stop("K must be between 1 and the number of columns in X.")
      }
    } else {
      res<- "no"
    }


    cat("Choose a method for feature selection:\n1. correlation (default)\n2. Combined Feature Selection (correlation and randomforest)\n")
    if(is.null(res2)){
      res2 <- readline(prompt="Enter the number for the method (1 for correlation method, 2 correlation and randomforest): ")
    }

    if(res2=="2"){
      cor_threshold <- as.numeric(readline(prompt="Enter the correlation threshold value (0-1) or enter 0 to use deafult value as 0.1: "))
    }

  }


  if(is.null(test_x)||is.null(test_y)){
    cat("please provide test data (test_x, test_y)\n")
    return(NULL)
  }

  valid_model_types <- c("linear", "logistic", "ridge", "lasso", "elastic_net")
  if (!(model_type %in% valid_model_types)) {
    cat("Error: Invalid model_type. Please provide one of the following valid model types:", paste(valid_model_types, collapse = ", "), "\n")
    return(NULL)
  }

  output_type <- ifelse(is.numeric(y),
                        ifelse(length(unique(y)) > 2, "Regression", "Classification"),
                        "Classification")
  print(output_type)

  models <- list()
  variable_importance <- numeric(length = ncol(X))
  names(variable_importance) <- names(X)
  pred <- numeric(nrow(X))
  for (i in 1:n_models) {
    sample <- bootstrap_sample(X,y, nrow(X))
    prs=prescreening(sample$sample_X,sample$sample_y,res=res,K=K,res2=res2,cor_threshold=cor_threshold)
    model <- switch(
      model_type,
      "linear" = simple_regression(prs$predictors,prs$response),
      "logistic" = simple_regression(prs$predictors,prs$response),
      "ridge" =ridge_regression_model(prs$predictors,prs$response),
      "lasso" = lasso_regression_model(prs$predictors,prs$response,lambda=lambda),
      "elastic_net" = elasticnet_regression_model(prs$predictors,prs$response,lambda=lambda,alpha=alpha),
    )


    models[[i]] <- model
    variable_importance[model$predictors] <- variable_importance[model$predictors] + 1
  }

  final_predictions <- predictions_models(test_x,test_y,models,model_type, output_type,lambda=lambda,K=K,alpha=alpha)
  return(list(predictions = final_predictions, variable_importance = variable_importance))
}
